{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 15px; \n",
    "            color: #FFC07F; \n",
    "            margin: 15px; \n",
    "            font-size: 1.5em; \n",
    "            display: fill; \n",
    "            border-radius: 10px; \n",
    "            border: 2px solid #FF9F00; \n",
    "            background-color: #2F2E41; \n",
    "            overflow: hidden; \n",
    "            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);\">\n",
    "    <center>\n",
    "        <a id=\"title\"></a>\n",
    "        <b style=\"font-size: 1.8em; color: #FFC07F;\">Neural Machine Translation</b><br><br>\n",
    "        <a id=\"top\"></a>\n",
    "        <b style=\"font-size: 1.4em; color: #FFC07F;\">Table of Contents</b>\n",
    "    </center>\n",
    "    <br>\n",
    "    <ul style=\"list-style-type: none; padding-left: 0;\">\n",
    "        <ul style=\"list-style-type: none; padding-left: 0;\">\n",
    "            <li style=\"padding: 8px 0;\">\n",
    "                <a href=\"#1\" style=\"color: #FFCC66; text-decoration: none;\">1 - Overview</a>\n",
    "            </li>\n",
    "            <ul style=\"list-style-type: none; padding-left: 20px;\">\n",
    "                <li style=\"padding: 8px 0;\">\n",
    "                    <a href=\"#1-1\" style=\"color: #FFCC66; text-decoration: none; font-weight: normal; font-size: 16px;\">1.1. Neural Machine Translation</a>\n",
    "                </li>\n",
    "                <li style=\"padding: 8px 0;\">\n",
    "                    <a href=\"#1-2\" style=\"color: #FFCC66; text-decoration: none; font-weight: normal; font-size: 16px;\">1.2. Overview</a>\n",
    "                </li>\n",
    "            </ul>\n",
    "        </ul>\n",
    "        <li style=\"padding: 8px 0;\">\n",
    "            <a href=\"#2\" style=\"color: #FFCC66; text-decoration: none;\">2 - Imports</a>\n",
    "        </li>\n",
    "        <ul style=\"list-style-type: none; padding-left: 0;\">\n",
    "            <li style=\"padding: 8px 0;\">\n",
    "                <a href=\"#3\" style=\"color: #FFCC66; text-decoration: none;\">3 - Data Preparation</a>\n",
    "            </li>\n",
    "            <ul style=\"list-style-type: none; padding-left: 20px;\">\n",
    "                <li style=\"padding: 8px 0;\">\n",
    "                    <a href=\"#3-1\" style=\"color: #FFCC66; text-decoration: none; font-weight: normal; font-size: 16px;\">3.1. Translating Human-Readable Dates into Machine-Readable Dates</a>\n",
    "                </li>\n",
    "                <li style=\"padding: 8px 0;\">\n",
    "                    <a href=\"#3-2\" style=\"color: #FFCC66; text-decoration: none; font-weight: normal; font-size: 16px;\">3.2. Dataset Overview</a>\n",
    "                </li>\n",
    "                <li style=\"padding: 8px 0;\">\n",
    "                    <a href=\"#3-3\" style=\"color: #FFCC66; text-decoration: none; font-weight: normal; font-size: 16px;\">3.3. Dataset Preprocessing</a>\n",
    "                </li>  \n",
    "            </ul>\n",
    "        </ul>\n",
    "        <ul style=\"list-style-type: none; padding-left: 0;\">\n",
    "            <li style=\"padding: 8px 0;\">\n",
    "                <a href=\"#4\" style=\"color: #FFCC66; text-decoration: none;\">4. Building the model</a>\n",
    "            </li>\n",
    "            <ul style=\"list-style-type: none; padding-left: 20px;\">\n",
    "                <li style=\"padding: 8px 0;\">\n",
    "                    <a href=\"#4-1\" style=\"color: #FFCC66; text-decoration: none; font-weight: normal; font-size: 16px;\">4.1. Neural Machine Translation with Attention</a>\n",
    "                </li>\n",
    "                <ul style=\"list-style-type: none; padding-left: 0px;\">\n",
    "                    <li style=\"padding: 8px 0;\">\n",
    "                        <a href=\"#4-2\" style=\"color: #FFCC66; text-decoration: none; font-weight: normal; font-size: 16px;\">4-2. Attention Mechanism</a>\n",
    "                    </li>\n",
    "                    <ul style=\"list-style-type: none; padding-left: 10px;\">\n",
    "                        <li style=\"padding: 8px 0;\">\n",
    "                            <a href=\"#4-2-1\" style=\"color: #FFCC66; text-decoration: none; font-weight: normal; font-size: 14px;\">4.2.1. Pre-attention and Post-attention LSTMs</a>\n",
    "                        </li>\n",
    "                        <li style=\"padding: 8px 0;\">\n",
    "                            <a href=\"#4-2-2\" style=\"color: #FFCC66; text-decoration: none; font-weight: normal; font-size: 14px;\">4.2.2. LSTM States: Hidden State and Cell State</a>\n",
    "                        </li>\n",
    "                        <li style=\"padding: 8px 0;\">\n",
    "                            <a href=\"#4-2-3\" style=\"color: #FFCC66; text-decoration: none; font-weight: normal; font-size: 14px;\">4.2.3. No Dependency on Previous Time Step Predictionse</a>\n",
    "                        </li>\n",
    "                        <li style=\"padding: 8px 0;\">\n",
    "                            <a href=\"#4-2-4\" style=\"color: #FFCC66; text-decoration: none; font-weight: normal; font-size: 14px;\">4.2.4. Concatenation of Hidden States from the Forward and Backward Pre-attention LSTMs</a>\n",
    "                        </li>\n",
    "                        <li style=\"padding: 8px 0;\">\n",
    "                            <a href=\"#4-2-5\" style=\"color: #FFCC66; text-decoration: none; font-weight: normal; font-size: 14px;\">4.2.5. Computing \"Energies\"</a>\n",
    "                        </li>\n",
    "                    </ul>\n",
    "                </ul>\n",
    "                <ul style=\"list-style-type: none; padding-left: 0px;\">\n",
    "                    <li style=\"padding: 8px 0;\">\n",
    "                        <a href=\"#4-3\" style=\"color: #FFCC66; text-decoration: none; font-weight: normal; font-size: 16px;\">4.3. Implementation Details</a>\n",
    "                    </li>\n",
    "                    <ul style=\"list-style-type: none; padding-left: 10px;\">\n",
    "                        <li style=\"padding: 8px 0;\">\n",
    "                            <a href=\"#4-3-1\" style=\"color: #FFCC66; text-decoration: none; font-weight: normal; font-size: 14px;\">4.3.1. one_step_attention</a>\n",
    "                        </li>\n",
    "                        <li style=\"padding: 8px 0;\">\n",
    "                            <a href=\"#4-3-2\" style=\"color: #FFCC66; text-decoration: none; font-weight: normal; font-size: 14px;\">4.3.2. Implementing `modelf()`</a>\n",
    "                        </li>\n",
    "                        <li style=\"padding: 8px 0;\">\n",
    "                            <a href=\"#4-3-3\" style=\"color: #FFCC66; text-decoration: none; font-weight: normal; font-size: 14px;\">4.3.3. Model Compilation</a>\n",
    "                        </li>\n",
    "                    </ul>\n",
    "                </ul>    \n",
    "            </ul>\n",
    "        </ul>\n",
    "        <ul style=\"list-style-type: none; padding-left: 0;\">\n",
    "            <li style=\"padding: 8px 0;\">\n",
    "                <a href=\"#5\" style=\"color: #FFCC66; text-decoration: none;\">5. Training the model</a>\n",
    "            </li>\n",
    "            <ul style=\"list-style-type: none; padding-left: 20px;\">\n",
    "                <li style=\"padding: 8px 0;\">\n",
    "                    <a href=\"#5-1\" style=\"color: #FFCC66; text-decoration: none; font-weight: normal; font-size: 16px;\">5.1. Define Inputs and Outputs, and Fit the Model</a>\n",
    "                </li>\n",
    "            </ul>\n",
    "        </ul>\n",
    "        <ul style=\"list-style-type: none; padding-left: 0;\">\n",
    "            <li style=\"padding: 8px 0;\">\n",
    "                <a href=\"#6\" style=\"color: #FFCC66; text-decoration: none;\">6. Visualizing Attention </a>\n",
    "            </li>\n",
    "            <ul style=\"list-style-type: none; padding-left: 20px;\">\n",
    "                <li style=\"padding: 8px 0;\">\n",
    "                    <a href=\"#6-1\" style=\"color: #FFCC66; text-decoration: none; font-weight: normal; font-size: 16px;\">6.1 - Extracting the Attention Weights from the Network</a>\n",
    "                </li>\n",
    "            </ul>\n",
    "        </ul>\n",
    "        <li style=\"padding: 8px 0;\">\n",
    "            <a href=\"#7\" style=\"color: #FFCC66; text-decoration: none;\">7. Conclusion</a>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; flex-direction: column; align-items: center; gap: 10px; margin-bottom: 20px;\">\n",
    "    <a href=\"mailto:umermjd11@gmail.com\" target=\"_blank\"><img src=\"https://img.shields.io/badge/Email-umermjd11@gmail.com-informational?style=for-the-badge&logo=gmail&logoColor=white&color=FF5722\" alt=\"Email Shield\"></a>\n",
    "    <a href=\"https://umermjd11.github.io/\" target=\"_blank\"><img src=\"https://img.shields.io/badge/Website-umermjd11.github.com-2F2E41?style=for-the-badge&logo=google-chrome&logoColor=white\" alt=\"Website Shield\"></a>\n",
    "    <a href=\"https://github.com/umermjd11\" target=\"_blank\"><img src=\"https://img.shields.io/badge/GitHub-umermjd11-181717?style=for-the-badge&logo=github&logoColor=white\" alt=\"GitHub Shield\"></a>\n",
    "    <a href=\"https://kaggle.com/umermjd11\" target=\"_blank\"><img src=\"https://img.shields.io/badge/Kaggle-umermjd11-20BEFF?style=for-the-badge&logo=kaggle&logoColor=white\" alt=\"Kaggle Shield\"></a>\n",
    "    <a href=\"https://linkedin.com/in/umermjd11\" target=\"_blank\"><img src=\"https://img.shields.io/badge/LinkedIn-umermjd11-blue?style=for-the-badge&logo=linkedin&logoColor=white\" alt=\"LinkedIn Shield\"></a>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<h1 style=\"background: #FFC07F; border: 0; color: #2F2E41; \n",
    "    box-shadow: 4px 4px 8px rgba(0, 0, 0, 0.3); \n",
    "    padding: 10px; border-radius: 10px; margin: 15px 0;\">\n",
    "    <center style=\"color: #2F2E41;\">1 - Overview</center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1.1\"></a>\n",
    "\n",
    "## 1.1. Neural Machine Translation\n",
    "\n",
    "In this section, we explore the development of a Neural Machine Translation (NMT) model designed to translate human-readable dates (e.g., \"25th of June, 2009\") into machine-readable formats (e.g., \"2009-06-25\"). The methodology centers on an attention-based model, a robust approach within sequence-to-sequence architectures.\n",
    "\n",
    "## 1.2. Overview\n",
    "\n",
    "Our objective is to leverage an attention mechanism to enable accurate translation between these date formats. Attention models, particularly within the sequence-to-sequence framework, enhance performance by dynamically focusing on relevant parts of the input sequence, improving the model's ability to handle complex language structures and dependencies. This approach builds on advances in neural translation developed in collaboration with NVIDIA's Deep Learning Institute.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "<h1 style=\"background: #FFC07F; border: 0; color: #2F2E41; \n",
    "    box-shadow: 4px 4px 8px rgba(0, 0, 0, 0.3); \n",
    "    padding: 10px; border-radius: 10px; margin: 15px 0;\">\n",
    "    <center style=\"color: #2F2E41;\">2. Imports</center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
    "from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from faker import Faker  # Faker library to generate synthetic data\n",
    "import random\n",
    "from tqdm import tqdm # tqdm library, used for creating progress bars\n",
    "from babel.dates import format_date # babel library is likely required by Faker for handling localized data formats like dates and numbers\n",
    "from nmt_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "<h1 style=\"background: #FFC07F; border: 0; color: #2F2E41; \n",
    "    box-shadow: 4px 4px 8px rgba(0, 0, 0, 0.3); \n",
    "    padding: 10px; border-radius: 10px; margin: 15px 0;\">\n",
    "    <center style=\"color: #2F2E41;\">3 - Data Preparation</center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3-1'></a>\n",
    "## 3.1. Translating Human-Readable Dates into Machine-Readable Dates\n",
    "\n",
    "In this section, we develop a model to translate human-readable dates into machine-readable formats. While such a model could be expanded to handle complex language translation tasks (e.g., English to Hindi), those applications typically require extensive datasets and prolonged training on GPUs. For the purpose of this study, we focus on the more constrained problem of date translation, allowing for efficient experimentation without large datasets.\n",
    "\n",
    "### Problem Scope\n",
    "\n",
    "Our model will take dates expressed in various formats (e.g., \"the 29th of August 1958\", \"03/30/1968\", \"24 JUNE 1987\") and translate them into a standardized machine-readable format (e.g., \"1958-08-29\", \"1968-03-30\", \"1987-06-24\"). The output format we aim to achieve is the widely accepted convention: YYYY-MM-DD.\n",
    "\n",
    "By employing a neural sequence-to-sequence architecture, we enable the model to generalize across a range of date expressions, learning to parse and reformat them into a standardized output.\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Data Efficiency**: This task provides a simplified domain to experiment with neural translation models without requiring vast amounts of data or GPU resources.\n",
    "- **Application to Real-World NLP Tasks**: The methods and architectures explored here form the basis for more complex NLP tasks, laying groundwork applicable to language translation, text processing, and data normalization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3-2'></a>\n",
    "\n",
    "## 3.2. Dataset Overview\n",
    "\n",
    "To train our model, we use a dataset containing 10,000 pairs of human-readable dates and their corresponding standardized, machine-readable formats. This dataset provides diverse examples to help the model generalize across various date expressions.\n",
    "\n",
    "Below, we present some sample entries from the dataset to illustrate the range of input formats and the target machine-readable output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 23903.96it/s]\n"
     ]
    }
   ],
   "source": [
    "m = 10000\n",
    "dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('10 nov 1992', '1992-11-10'),\n",
       " ('23.07.70', '1970-07-23'),\n",
       " ('4/12/15', '2015-04-12'),\n",
       " ('wednesday may 21 1986', '1986-05-21'),\n",
       " ('tuesday march 20 1990', '1990-03-20'),\n",
       " ('sunday august 17 1980', '1980-08-17'),\n",
       " ('sunday january 21 2001', '2001-01-21'),\n",
       " ('15 nov 1978', '1978-11-15'),\n",
       " ('26 oct 1976', '1976-10-26'),\n",
       " ('sunday october 3 1993', '1993-10-03')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have loaded the following key components for model development:\n",
    "\n",
    "- `dataset`: A list containing tuples of the form (human-readable date, machine-readable date).\n",
    "- `human_vocab`: A dictionary that maps each character in the human-readable dates to a unique integer index.\n",
    "- `machine_vocab`: A dictionary that maps each character in the machine-readable dates to an integer index.\n",
    "    - **Note**: The indices in `machine_vocab` are not necessarily aligned with those in `human_vocab`.\n",
    "- `inv_machine_vocab`: The inverse mapping of `machine_vocab`, allowing translation from indices back to characters.\n",
    "\n",
    "<a id='3-3'></a>\n",
    "\n",
    "## 3.3. Dataset Preprocessing \n",
    "\n",
    "To prepare the data for model training, we will map the raw text data into integer indices. We define the following parameters for sequence lengths:\n",
    "\n",
    "- \\( T_x = 30 \\): This parameter represents the maximum length of the human-readable date sequence. For inputs exceeding this length, truncation will be applied.\n",
    "- \\( T_y = 10 \\): This value reflects the standardized length of the target format \"YYYY-MM-DD\", which contains 10 characters.\n",
    "\n",
    "The next steps involve transforming each date into indexed representations to facilitate model processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '.': 1,\n",
       " '/': 2,\n",
       " '0': 3,\n",
       " '1': 4,\n",
       " '2': 5,\n",
       " '3': 6,\n",
       " '4': 7,\n",
       " '5': 8,\n",
       " '6': 9,\n",
       " '7': 10,\n",
       " '8': 11,\n",
       " '9': 12,\n",
       " 'a': 13,\n",
       " 'b': 14,\n",
       " 'c': 15,\n",
       " 'd': 16,\n",
       " 'e': 17,\n",
       " 'f': 18,\n",
       " 'g': 19,\n",
       " 'h': 20,\n",
       " 'i': 21,\n",
       " 'j': 22,\n",
       " 'l': 23,\n",
       " 'm': 24,\n",
       " 'n': 25,\n",
       " 'o': 26,\n",
       " 'p': 27,\n",
       " 'r': 28,\n",
       " 's': 29,\n",
       " 't': 30,\n",
       " 'u': 31,\n",
       " 'v': 32,\n",
       " 'w': 33,\n",
       " 'y': 34,\n",
       " '<unk>': 35,\n",
       " '<pad>': 36}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-13 10:12:49.799968: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (10000, 30)\n",
      "Y.shape: (10000, 10)\n",
      "Xoh.shape: (10000, 30, 37)\n",
      "Yoh.shape: (10000, 10, 11)\n"
     ]
    }
   ],
   "source": [
    "Tx = 30\n",
    "Ty = 10\n",
    "X, Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)\n",
    "\n",
    "print(\"X.shape:\", X.shape)\n",
    "print(\"Y.shape:\", Y.shape)\n",
    "print(\"Xoh.shape:\", Xoh.shape)\n",
    "print(\"Yoh.shape:\", Yoh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data processing stage has yielded the following components:\n",
    "\n",
    "- **`X`**: A processed array representing the human-readable dates in the training set.\n",
    "    - Each character in $X$ is mapped to an integer index based on `human_vocab`.\n",
    "    - Padding is applied to ensure each date has a length of $T_x$ using a special padding character (`< pad >`).\n",
    "    - $X.\\text{shape} = (m, T_x)$, where $m$ denotes the number of training examples in each batch.\n",
    "\n",
    "- **`Y`**: A processed array for the machine-readable date outputs.\n",
    "    - Each character in $Y$ is mapped to an integer index as defined in `machine_vocab`.\n",
    "    - $Y.\\text{shape} = (m, T_y)$.\n",
    "\n",
    "- **`Xoh`**: The one-hot encoded version of $X$.\n",
    "    - Each index in $X$ is converted to a one-hot vector, with the corresponding index position set to 1 and all others to 0.\n",
    "    - $Xoh.\\text{shape} = (m, T_x, \\text{len}(\\text{human\\_vocab}))$.\n",
    "\n",
    "- **`Yoh`**: The one-hot encoded version of $Y$.\n",
    "    - Each index in $Y$ is transformed into its one-hot representation.\n",
    "    - $Yoh.\\text{shape} = (m, T_y, \\text{len}(\\text{machine\\_vocab}))$.\n",
    "    - Here, $\\text{len}(\\text{machine\\_vocab}) = 11$, accounting for the 10 numeric digits (0–9) and the `-` symbol.\n",
    "\n",
    "These processed arrays will serve as the inputs for training the model, enabling it to learn accurate mappings between diverse date formats.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better understand the preprocessing results, we can examine some examples from the training set. By adjusting the `index` parameter in the following cell, we can navigate through the dataset to view different source and target date pairs in their preprocessed forms.\n",
    "\n",
    "This exploration provides insights into how diverse date formats are transformed into standardized representations, aiding the model in learning consistent mappings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source date: 10 nov 1992\n",
      "Target date: 1992-11-10\n",
      "\n",
      "Source after preprocessing (indices): [ 4  3  0 25 26 32  0  4 12 12  5 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "Target after preprocessing (indices): [ 2 10 10  3  0  2  2  0  2  1]\n",
      "\n",
      "Source after preprocessing (one-hot): [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "Target after preprocessing (one-hot): [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "print(\"Source date:\", dataset[index][0])\n",
    "print(\"Target date:\", dataset[index][1])\n",
    "print()\n",
    "print(\"Source after preprocessing (indices):\", X[index])\n",
    "print(\"Target after preprocessing (indices):\", Y[index])\n",
    "print()\n",
    "print(\"Source after preprocessing (one-hot):\", Xoh[index])\n",
    "print(\"Target after preprocessing (one-hot):\", Yoh[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "<h1 style=\"background: #FFC07F; border: 0; color: #2F2E41; \n",
    "    box-shadow: 4px 4px 8px rgba(0, 0, 0, 0.3); \n",
    "    padding: 10px; border-radius: 10px; margin: 15px 0;\">\n",
    "    <center style=\"color: #2F2E41;\">4. Building the model</center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4-1'></a>\n",
    "\n",
    "## 4.1. Neural Machine Translation with Attention\n",
    "\n",
    "In human translation, a translator does not process an entire text in one go before beginning to translate. Instead, they focus on smaller parts, often re-reading sections of the original text as they work through the translation. Similarly, in Neural Machine Translation, the attention mechanism guides the model to concentrate on relevant parts of the input sequence during each translation step.\n",
    "\n",
    "The attention mechanism dynamically adjusts the model’s focus, effectively enhancing its ability to capture dependencies between input and output sequences.\n",
    "\n",
    "<a id='4-2'></a>\n",
    "\n",
    "## 4-2. Attention Mechanism\n",
    "\n",
    "In this section, we implement the attention mechanism. This mechanism facilitates the model's focus on specific parts of the input sequence at each output timestep, aiding in the translation process.\n",
    "\n",
    "- The left diagram below illustrates the structure of an attention-based model.\n",
    "- The right diagram depicts the calculation of the attention variables $\\alpha^{\\langle t, t' \\rangle}$ during an \"attention\" step.\n",
    "- These attention variables are then used to compute the context vector $context^{\\langle t \\rangle}$ for each timestep in the output sequence, where $t = 1, \\ldots, T_y$.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "<table>\n",
    "<tr>\n",
    "<td> \n",
    "<img src=\"https://raw.githubusercontent.com/umermjd11/DLC5M3A1/master/images/attn_model.png\" style=\"width:500px;height:500px;\"> <br>\n",
    "</td> \n",
    "<td> \n",
    "<img src=\"https://raw.githubusercontent.com/umermjd11/DLC5M3A1/master/images/attn_mechanism.png\" style=\"width:500px;height:500px;\"> <br>\n",
    "</td> \n",
    "</tr>\n",
    "</table>\n",
    "<caption>\n",
    "    <font color=\"#00796b\" style=\"font-size: 1.2em; font-weight: bold;\">\n",
    "      <b>Figure 1</b>: Neural Machine Translation with Attention\n",
    "    </font>\n",
    "  </caption>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4-2-1\"></a>\n",
    "\n",
    "### 4.2.1. Pre-attention and Post-attention LSTMs\n",
    "\n",
    "The model incorporates the following key architectural features, as shown in the diagram:\n",
    "\n",
    "- **Pre-attention Bi-LSTM**: Positioned at the bottom of the left diagram, this Bi-directional LSTM operates *before* the attention mechanism.\n",
    "    - It processes the input sequence through $T_x$ timesteps.\n",
    "    - The attention mechanism, highlighted in the middle of the diagram, applies after this layer.\n",
    "\n",
    "- **Post-attention LSTM**: Located at the top of the diagram, this LSTM layer follows the attention mechanism and processes the output sequence.\n",
    "    - It operates over $T_y$ timesteps, allowing the model to generate an output sequence based on the attention-modified input.\n",
    "\n",
    "- **State Propagation in Post-attention LSTM**: The post-attention LSTM maintains a continuous flow of information by passing the hidden state $s^{\\langle t \\rangle}$ and cell state $c^{\\langle t \\rangle}$ across each timestep.\n",
    "\n",
    "This layered structure allows the model to effectively utilize both past and future context from the input sequence and refine its focus with the attention mechanism before producing each output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4-2-2\"></a>\n",
    "\n",
    "### 4.2.2. LSTM States: Hidden State and Cell State\n",
    "\n",
    "\n",
    "- In the post-attention sequence model, a basic RNN may be used, which outputs only the hidden state $s^{\\langle t \\rangle}$ at each timestep. A basic RNN does not utilize a separate cell state.\n",
    "  \n",
    "- In contrast, we implement an LSTM instead of a basic RNN. The LSTM, by design, maintains two states:\n",
    "    - The **hidden state** $s^{\\langle t \\rangle}$, which represents the output of the model at each timestep.\n",
    "    - The **cell state** $c^{\\langle t \\rangle}$, which acts as the memory of the network, enabling it to retain information over longer sequences.\n",
    "\n",
    "The dual presence of the hidden state and cell state allows the LSTM to capture more complex temporal dependencies, improving the model’s ability to learn long-term relationships within the input sequence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4-2-3\"></a>\n",
    "\n",
    "### 4.2.3. No Dependency on Previous Time Step Predictions\n",
    "\n",
    "- In contrast to previous text generation models, where predictions from the previous timestep $y^{\\langle t-1 \\rangle}$ were used as input for generating the next character, the post-attention LSTM in this model operates differently.\n",
    "  \n",
    "- At each timestep $t$, the post-attention LSTM does not take the previous timestep's prediction $y^{\\langle t-1 \\rangle}$ as input. Instead, it only takes the hidden state $s^{\\langle t \\rangle}$ and cell state $c^{\\langle t \\rangle}$ from the previous timestep.\n",
    "\n",
    "- This design choice is driven by the nature of the task: unlike language generation, where adjacent characters are often highly correlated, there is less dependency between consecutive characters in a machine-readable date format such as YYYY-MM-DD. Therefore, it is not necessary for the model to rely on previous predictions to generate the next output character.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4-2-4\"></a>\n",
    "\n",
    "### 4.2.4. Concatenation of Hidden States from the Forward and Backward Pre-attention LSTMs\n",
    "\n",
    "- $\\overrightarrow{a}^{\\langle t \\rangle}$: The hidden state of the forward-direction, pre-attention LSTM.\n",
    "- $\\overleftarrow{a}^{\\langle t \\rangle}$: The hidden state of the backward-direction, pre-attention LSTM.\n",
    "- $a^{\\langle t \\rangle} = [\\overrightarrow{a}^{\\langle t \\rangle}, \\overleftarrow{a}^{\\langle t \\rangle}]$: The concatenation of the activations from both the forward-direction $\\overrightarrow{a}^{\\langle t \\rangle}$ and backward-direction $\\overleftarrow{a}^{\\langle t \\rangle}$ of the pre-attention Bi-LSTM.\n",
    "\n",
    "This concatenation allows the model to leverage context from both the past and future, enhancing the representation of each timestep in the sequence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4-2-5\"></a>\n",
    "\n",
    "### 4.2.5. Computing \"Energies\" $e^{\\langle t, t' \\rangle}$ as a Function of $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t' \\rangle}$\n",
    "\n",
    "- In the \"Attention Model\", the definition of the energy function $e^{\\langle t, t' \\rangle}$, which is computed as a function of the hidden states $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t' \\rangle}$:\n",
    "    - $e^{\\langle t, t' \\rangle}$ is referred to as the \"energies\" variable.\n",
    "    - $s^{\\langle t-1 \\rangle}$ represents the hidden state of the post-attention LSTM at the previous timestep.\n",
    "    - $a^{\\langle t' \\rangle}$ denotes the hidden state of the pre-attention LSTM at timestep $t'$.\n",
    "    - These two vectors, $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t' \\rangle}$, are fed into a simple neural network, which learns the function that outputs the energy $e^{\\langle t, t' \\rangle}$.\n",
    "    - The computed energy $e^{\\langle t, t' \\rangle}$ is then used in calculating the attention $a^{\\langle t, t' \\rangle}$, which determines the degree to which the output $y^{\\langle t \\rangle}$ should focus on the hidden state $a^{\\langle t' \\rangle}$ of the pre-attention LSTM at timestep $t'$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The diagram on the right side of Figure 1 illustrates the use of a `RepeatVector` node to replicate the hidden state $s^{\\langle t-1 \\rangle}$ $T_x$ times. \n",
    "- This is followed by the `Concatenation` operation, which combines $s^{\\langle t-1 \\rangle}$ with the hidden state $a^{\\langle t \\rangle}$ from the pre-attention LSTM.\n",
    "- The concatenated vector of $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t \\rangle}$ is then passed through a \"Dense\" layer, which computes the energy values $e^{\\langle t, t' \\rangle}$.\n",
    "- These energy values $e^{\\langle t, t' \\rangle}$ are subsequently passed through a softmax function to compute the attention weights $\\alpha^{\\langle t, t' \\rangle}$.\n",
    "- It is important to note that the diagram does not explicitly label the variable $e^{\\langle t, t' \\rangle}$, but it is located above the Dense layer and below the Softmax layer in the diagram on the right half of Figure 1.\n",
    "- We will further explain how to use `RepeatVector` and `Concatenation` in Keras in the upcoming sections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4-3'></a>\n",
    "\n",
    "## 4.3. Implementation Details\n",
    "\n",
    "Let us begin implementing the neural translator by defining the function `one_step_attention()` and the model architecture.\n",
    "\n",
    "<a id='4-3-1'></a>\n",
    "\n",
    "### 4.3.1. one_step_attention\n",
    "\n",
    "The inputs to the `one_step_attention` function at time step $t$ are:\n",
    "- $[a^{<1>}, a^{<2>}, ..., a^{<T_x>}]$: the sequence of hidden states from the pre-attention Bi-LSTM.\n",
    "- $s^{<t-1>}$: the previous hidden state of the post-attention LSTM.\n",
    "\n",
    "The function `one_step_attention` computes:\n",
    "- $[\\alpha^{<t,1>}, \\alpha^{<t,2>}, ..., \\alpha^{<t,T_x>}]$: the attention weights corresponding to each timestep $t'$.\n",
    "- $context^{\\langle t \\rangle}$: the context vector, computed as the weighted sum of the pre-attention hidden states, given by:\n",
    "\n",
    "$$\n",
    "context^{<t>} = \\sum_{t' = 1}^{T_x} \\alpha^{<t,t'>} a^{<t'>} \\tag{1}\n",
    "$$\n",
    "\n",
    "##### Clarifying 'context' and 'c'\n",
    "- The context vector is usually denoted as $c^{\\langle t \\rangle}$.\n",
    "- To avoid confusion with the internal memory cell variable of the post-attention LSTM, we refer to the context vector as $context^{\\langle t \\rangle}$ in this implementation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing `one_step_attention()`\n",
    "\n",
    "now our task is to implement the function `one_step_attention()`.\n",
    "\n",
    "- The function `model()` will invoke the layers within `one_step_attention()` for $T_y$ iterations using a for-loop.\n",
    "- It is crucial that all $T_y$ iterations share the same weights. This means:\n",
    "    - The weights should not be reinitialized with each iteration.\n",
    "    - All $T_y$ steps should use shared weights, ensuring consistency throughout the process.\n",
    "\n",
    "##### Implementing Layers with Shared Weights in Keras\n",
    "\n",
    "To implement layers with shared weights in Keras, we will follow these guidelines:\n",
    "\n",
    "1. **Layer Definition Scope**: Define the layer objects in a variable scope outside the `one_step_attention()` function. For example, defining the layers as global variables ensures that they retain their weights across iterations.\n",
    "    - While defining these layers inside the `model()` function would technically work, for ease of troubleshooting, we recommend defining them as global variables.\n",
    "\n",
    "2. **Using Defined Layers**: Once the layers are defined globally, we can use them when propagating the input through the network.\n",
    "\n",
    "\n",
    "##### Layer Function Calls\n",
    "\n",
    "You can refer to the Keras documentation for further details on each layer. Below are examples of how to call the layers in your implementation:\n",
    "\n",
    "- **RepeatVector**: Replicates the input multiple times along a new axis.\n",
    "    ```python\n",
    "    var_repeated = repeat_layer(var1)\n",
    "    ```\n",
    "    [Keras RepeatVector Documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RepeatVector)\n",
    "\n",
    "- **Concatenate**: Concatenates a list of tensors along a specified axis.\n",
    "    ```python\n",
    "    concatenated_vars = concatenate_layer([var1, var2, var3])\n",
    "    ```\n",
    "    [Keras Concatenate Documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate)\n",
    "\n",
    "- **Dense**: Applies a linear transformation to the input.\n",
    "    ```python\n",
    "    var_out = dense_layer(var_in)\n",
    "    ```\n",
    "    [Keras Dense Documentation](https://keras.io/layers/core/#dense)\n",
    "\n",
    "- **Activation**: Applies an activation function to the input.\n",
    "    ```python\n",
    "    activation = activation_layer(var_in)\n",
    "    ```\n",
    "    [Keras Activation Documentation](https://keras.io/layers/core/#activation)\n",
    "\n",
    "- **Dot**: Computes the dot product of two tensors.\n",
    "    ```python\n",
    "    dot_product = dot_layer([var1, var2])\n",
    "    ```\n",
    "    [Keras Dot Documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined shared layers as global variables\n",
    "repeator = RepeatVector(Tx)\n",
    "concatenator = Concatenate(axis=-1)\n",
    "densor1 = Dense(10, activation = \"tanh\")\n",
    "densor2 = Dense(1, activation = \"relu\")\n",
    "activator = Activation(softmax, name='attention_weights') # We are using a custom softmax(axis = 1) loaded in this notebook\n",
    "dotor = Dot(axes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "\n",
    "def one_step_attention(a: np.ndarray, s_prev: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Performs one step of attention, outputting a context vector computed as a dot product of \n",
    "    the attention weights \"alphas\" and the hidden states \"a\" of the Bi-LSTM.\n",
    "    \n",
    "    Arguments:\n",
    "    a -- Hidden state output of the Bi-LSTM, numpy-array of shape (m, Tx, 2*n_a)\n",
    "    s_prev -- Previous hidden state of the (post-attention) LSTM, numpy-array of shape (m, n_s)\n",
    "    \n",
    "    Returns:\n",
    "    context -- Context vector, input to the next (post-attention) LSTM cell, numpy-array of shape (m, 2*n_a)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Repeat s_prev across the time steps dimension\n",
    "    s_prev_repeated = repeator(s_prev)  # Shape: (m, Tx, n_s)\n",
    "    \n",
    "    # Step 2: Concatenate the hidden states 'a' and the repeated s_prev along the last axis\n",
    "    concat = concatenator([a, s_prev_repeated])  # Shape: (m, Tx, 2*n_a + n_s)\n",
    "    \n",
    "    # Step 3: Compute the intermediate energies by passing 'concat' through the first dense layer\n",
    "    e = densor1(concat)  # Shape: (m, Tx, 64), assuming 64 units in densor1\n",
    "    \n",
    "    # Step 4: Compute the final energies for the attention weights\n",
    "    energies = densor2(e)  # Shape: (m, Tx, 1)\n",
    "    \n",
    "    # Step 5: Apply the activation function (e.g., softmax) to obtain the attention weights\n",
    "    alphas = activator(energies)  # Shape: (m, Tx, 1), normalized across Tx dimension\n",
    "    \n",
    "    # Step 6: Compute the context vector as a weighted sum of 'a' based on attention weights 'alphas'\n",
    "    context = dotor([alphas, a])  # Shape: (m, 2*n_a)\n",
    "    \n",
    "    return context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "# UNIT TEST\n",
    "def one_step_attention_test(target):\n",
    "\n",
    "    m = 10\n",
    "    Tx = 30\n",
    "    n_a = 32\n",
    "    n_s = 64\n",
    "    #np.random.seed(10)\n",
    "    a = np.random.uniform(1, 0, (m, Tx, 2 * n_a)).astype(np.float32)\n",
    "    s_prev =np.random.uniform(1, 0, (m, n_s)).astype(np.float32) * 1\n",
    "    context = target(a, s_prev)\n",
    "    \n",
    "    assert tf.is_tensor(context), \"Unexpected type. It should be a Tensor\"\n",
    "    assert tuple(context.shape) == (m, 1, n_s), \"Unexpected output shape\"\n",
    "    assert np.all(context.numpy() > 0), \"All output values must be > 0 in this example\"\n",
    "    assert np.all(context.numpy() < 1), \"All output values must be < 1 in this example\"\n",
    "\n",
    "    #assert np.allclose(context[0][0][0:5].numpy(), [0.50877404, 0.57160693, 0.45448175, 0.50074816, 0.53651875]), \"Unexpected values in the result\"\n",
    "    print(\"\\033[92mAll tests passed!\")\n",
    "    \n",
    "one_step_attention_test(one_step_attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4-3-2'></a>\n",
    "\n",
    "### 4.3.2. Implementing `modelf()`\n",
    "\n",
    "Now, we will implement the function `modelf()` as outlined in Figure 1 and the instructions provided.\n",
    "\n",
    "#### Function Overview\n",
    "\n",
    "The `modelf()` function performs the following steps:\n",
    "\n",
    "1. **Bi-LSTM Processing**: The input is first passed through a Bidirectional Long Short-Term Memory (Bi-LSTM) layer to produce a sequence of context vectors, denoted as $[a^{<1>}, a^{<2>}, ..., a^{<T_x>}]$.\n",
    "   \n",
    "2. **Recurrent Attention Loop**: The function then calls the `one_step_attention()` function $T_y$ times using a `for` loop. For each iteration of the loop:\n",
    "    - The computed context vector $context^{<t>}$ is passed to the post-attention LSTM.\n",
    "    - The output of the post-attention LSTM is passed through a Dense layer with a softmax activation.\n",
    "    - The softmax activation generates a prediction $\\hat{y}^{<t>}$. \n",
    "\n",
    "#### Layer Sharing\n",
    "\n",
    "In previous codes cells above, we have defined global layers that will share weights across the $T_y$ iterations within the `modelf()` function. These layers will ensure that the weights are not reinitialized during each iteration, promoting consistent behavior across all steps.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a = 32 # number of units for the pre-attention, bi-directional LSTM's hidden state 'a'\n",
    "n_s = 64 # number of units for the post-attention LSTM's hidden state \"s\"\n",
    "\n",
    "# Please note, this is the post attention LSTM cell.  \n",
    "post_attention_LSTM_cell = LSTM(n_s, return_state = True) # Please do not modify this global variable.\n",
    "output_layer = Dense(len(machine_vocab), activation=softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use these layers $T_y$ times in a `for` loop to generate the outputs, and their parameters will not be reinitialized. we will have to carry out the following steps: \n",
    "\n",
    "1. Propagate the input `X` into a bi-directional LSTM.\n",
    "    * [Bidirectional](https://keras.io/layers/wrappers/#bidirectional) \n",
    "    * [LSTM](https://keras.io/layers/recurrent/#lstm)\n",
    "    * Remember that we want the LSTM to return a full sequence instead of just the last hidden state.  \n",
    "    \n",
    "Sample code:\n",
    "\n",
    "```Python\n",
    "sequence_of_hidden_states = Bidirectional(LSTM(units=..., return_sequences=...))(the_input_X)\n",
    "```\n",
    "    \n",
    "2. Iterate for $t = 0, \\cdots, T_y-1$: \n",
    "    1. Call `one_step_attention()`, passing in the sequence of hidden states $[a^{\\langle 1 \\rangle},a^{\\langle 2 \\rangle}, ..., a^{ \\langle T_x \\rangle}]$ from the pre-attention bi-directional LSTM, and the previous hidden state $s^{<t-1>}$ from the post-attention LSTM to calculate the context vector $context^{<t>}$.\n",
    "    2. Give $context^{<t>}$ to the post-attention LSTM cell. \n",
    "        - Remember to pass in the previous hidden-state $s^{\\langle t-1\\rangle}$ and cell-states $c^{\\langle t-1\\rangle}$ of this LSTM \n",
    "        * This outputs the new hidden state $s^{<t>}$ and the new cell state $c^{<t>}$.  \n",
    "\n",
    "        Sample code:\n",
    "        ```Python\n",
    "        next_hidden_state, _ , next_cell_state = \n",
    "            post_attention_LSTM_cell(inputs=..., initial_state=[prev_hidden_state, prev_cell_state])\n",
    "        ```   \n",
    "\n",
    "    3. Apply a dense, softmax layer to $s^{<t>}$, get the output.  \n",
    "        Sample code:\n",
    "        ```Python\n",
    "        output = output_layer(inputs=...)\n",
    "        ```\n",
    "    4. Save the output by adding it to the list of outputs.\n",
    "\n",
    "3. Create our Keras model instance.\n",
    "    * It should have three inputs:\n",
    "        * `X`, the one-hot encoded inputs to the model, of shape ($T_{x}, humanVocabSize)$\n",
    "        * $s^{\\langle 0 \\rangle}$, the initial hidden state of the post-attention LSTM\n",
    "        * $c^{\\langle 0 \\rangle}$, the initial cell state of the post-attention LSTM\n",
    "    * The output is the list of outputs.  \n",
    "    Sample code\n",
    "    ```Python\n",
    "    model = Model(inputs=[...,...,...], outputs=...)\n",
    "    ```\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from typing import List\n",
    "\n",
    "def modelf(Tx: int, Ty: int, n_a: int, n_s: int, human_vocab_size: int, machine_vocab_size: int) -> Model:\n",
    "    \"\"\"\n",
    "    Creates an attention-based sequence-to-sequence model.\n",
    "\n",
    "    Arguments:\n",
    "    Tx -- length of the input sequence\n",
    "    Ty -- length of the output sequence\n",
    "    n_a -- hidden state size of the Bi-LSTM\n",
    "    n_s -- hidden state size of the post-attention LSTM\n",
    "    human_vocab_size -- size of the input vocabulary\n",
    "    machine_vocab_size -- size of the output vocabulary\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 0: Define the inputs\n",
    "    X = Input(shape=(Tx, human_vocab_size), name=\"Input_Sequence\")\n",
    "    s0 = Input(shape=(n_s,), name=\"s0\")  # Initial hidden state of LSTM\n",
    "    c0 = Input(shape=(n_s,), name=\"c0\")  # Initial cell state of LSTM\n",
    "    s, c = s0, c0  # Initialize s and c with s0 and c0\n",
    "    \n",
    "    # Initialize list of outputs\n",
    "    outputs: List[tf.Tensor] = []\n",
    "\n",
    "    \n",
    "    # Step 1: Define the Bi-LSTM layer\n",
    "    a = Bidirectional(LSTM(n_a, return_sequences=True), name=\"BiLSTM\")(X)\n",
    "    \n",
    "    # Step 2: Loop through each time step to generate outputs\n",
    "    for t in range(Ty):\n",
    "        # Step 2.A: Compute the context vector via attention\n",
    "        context = one_step_attention(a, s)\n",
    "        \n",
    "        # Step 2.B: Apply the post-attention LSTM with the context vector\n",
    "        s, _, c = post_attention_LSTM_cell(context, initial_state=[s, c])\n",
    "        \n",
    "        # Step 2.C: Apply the output Dense layer to get the output at time step t\n",
    "        out = output_layer(s)\n",
    "        \n",
    "        # Step 2.D: Append current output to the outputs list\n",
    "        outputs.append(out)\n",
    "    \n",
    "    # Step 3: Define and compile the model\n",
    "    model = Model(inputs=[X, s0, c0], outputs=outputs, name=\"Attention_Model\")\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['InputLayer', (None, 30, 37), 0], ['InputLayer', (None, 64), 0], ['Bidirectional', (None, 30, 64), 17920], ['RepeatVector', (None, 30, 64), 0, 30], ['Concatenate', (None, 30, 128), 0], ['Dense', (None, 30, 10), 1290, 'tanh'], ['Dense', (None, 30, 1), 11, 'relu'], ['Activation', (None, 30, 1), 0], ['Dot', (None, 1, 64), 0], ['InputLayer', (None, 64), 0], ['LSTM', [(None, 64), (None, 64), (None, 64)], 33024, [(None, 64), (None, 64), (None, 64)], 'tanh'], ['Dense', (None, 11), 715, 'softmax']]\n",
      "\u001b[32mAll tests passed!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# UNIT TEST\n",
    "from test_utils import *\n",
    "\n",
    "def modelf_test(target):\n",
    "    m = 10\n",
    "    Tx = 30\n",
    "    n_a = 32\n",
    "    n_s = 64\n",
    "    len_human_vocab = 37\n",
    "    len_machine_vocab = 11\n",
    "    \n",
    "    \n",
    "    model = target(Tx, Ty, n_a, n_s, len_human_vocab, len_machine_vocab)\n",
    "    \n",
    "    print(summary(model))\n",
    "\n",
    "    \n",
    "    expected_summary = [['InputLayer', (None, 30, 37), 0],\n",
    "                         ['InputLayer', (None, 64), 0],\n",
    "                         ['Bidirectional', (None, 30, 64), 17920],\n",
    "                         ['RepeatVector', (None, 30, 64), 0, 30],\n",
    "                         ['Concatenate', (None, 30, 128), 0],\n",
    "                         ['Dense', (None, 30, 10), 1290, 'tanh'],\n",
    "                         ['Dense', (None, 30, 1), 11, 'relu'],\n",
    "                         ['Activation', (None, 30, 1), 0],\n",
    "                         ['Dot', (None, 1, 64), 0],\n",
    "                         ['InputLayer', (None, 64), 0],\n",
    "                         ['LSTM',[(None, 64), (None, 64), (None, 64)], 33024,[(None, 64), (None, 64), (None, 64)],'tanh'],\n",
    "                         ['Dense', (None, 11), 715, 'softmax']]\n",
    "\n",
    "    comparator(summary(model), expected_summary)\n",
    "    \n",
    "\n",
    "modelf_test(modelf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modelf(Tx, Ty, n_a, n_s, len(human_vocab), len(machine_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a summary of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Attention_Model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Attention_Model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Input_Sequence      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ s0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ BiLSTM              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">17,920</span> │ Input_Sequence[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ repeat_vector       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ s0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)      │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">181</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">183</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">186</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">188</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">18…</span> │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">18…</span> │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">18…</span> │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">18…</span> │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">18…</span> │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">18…</span> │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">18…</span> │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">18…</span> │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">18…</span> │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">18…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>]… │\n",
       "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">181</span>]… │\n",
       "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>]… │\n",
       "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">183</span>]… │\n",
       "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>]… │\n",
       "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>]… │\n",
       "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">186</span>]… │\n",
       "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>]… │\n",
       "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">188</span>]… │\n",
       "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">189</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">181</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">183</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">186</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">188</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">189</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention_weights   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">181</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">183</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">186</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">188</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">189</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ c0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),       │            │ s0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)]       │            │ c0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
       "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">181</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],   │\n",
       "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">181</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">181</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],   │\n",
       "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">183</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],   │\n",
       "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">183</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">183</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],   │\n",
       "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],   │\n",
       "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">186</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],   │\n",
       "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">186</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">186</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],   │\n",
       "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">188</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],   │\n",
       "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">189</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">188</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">188</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">715</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">181</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">183</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">186</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">188</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">189</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Input_Sequence      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m37\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ s0 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ BiLSTM              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m17,920\u001b[0m │ Input_Sequence[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ repeat_vector       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ s0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
       "│ (\u001b[38;5;33mRepeatVector\u001b[0m)      │                   │            │ lstm_1[\u001b[38;5;34m180\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m181\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m182\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m183\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m184\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m185\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m186\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m187\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m188\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ repeat_vector[\u001b[38;5;34m18…\u001b[0m │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ repeat_vector[\u001b[38;5;34m18…\u001b[0m │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ repeat_vector[\u001b[38;5;34m18…\u001b[0m │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ repeat_vector[\u001b[38;5;34m18…\u001b[0m │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ repeat_vector[\u001b[38;5;34m18…\u001b[0m │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ repeat_vector[\u001b[38;5;34m18…\u001b[0m │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ repeat_vector[\u001b[38;5;34m18…\u001b[0m │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ repeat_vector[\u001b[38;5;34m18…\u001b[0m │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ repeat_vector[\u001b[38;5;34m18…\u001b[0m │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ repeat_vector[\u001b[38;5;34m18…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m10\u001b[0m)    │      \u001b[38;5;34m1,290\u001b[0m │ concatenate[\u001b[38;5;34m180\u001b[0m]… │\n",
       "│                     │                   │            │ concatenate[\u001b[38;5;34m181\u001b[0m]… │\n",
       "│                     │                   │            │ concatenate[\u001b[38;5;34m182\u001b[0m]… │\n",
       "│                     │                   │            │ concatenate[\u001b[38;5;34m183\u001b[0m]… │\n",
       "│                     │                   │            │ concatenate[\u001b[38;5;34m184\u001b[0m]… │\n",
       "│                     │                   │            │ concatenate[\u001b[38;5;34m185\u001b[0m]… │\n",
       "│                     │                   │            │ concatenate[\u001b[38;5;34m186\u001b[0m]… │\n",
       "│                     │                   │            │ concatenate[\u001b[38;5;34m187\u001b[0m]… │\n",
       "│                     │                   │            │ concatenate[\u001b[38;5;34m188\u001b[0m]… │\n",
       "│                     │                   │            │ concatenate[\u001b[38;5;34m189\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │         \u001b[38;5;34m11\u001b[0m │ dense[\u001b[38;5;34m180\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ dense[\u001b[38;5;34m181\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ dense[\u001b[38;5;34m182\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ dense[\u001b[38;5;34m183\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ dense[\u001b[38;5;34m184\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ dense[\u001b[38;5;34m185\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ dense[\u001b[38;5;34m186\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ dense[\u001b[38;5;34m187\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ dense[\u001b[38;5;34m188\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ dense[\u001b[38;5;34m189\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention_weights   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m180\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │ dense_1[\u001b[38;5;34m181\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ dense_1[\u001b[38;5;34m182\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ dense_1[\u001b[38;5;34m183\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ dense_1[\u001b[38;5;34m184\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ dense_1[\u001b[38;5;34m185\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ dense_1[\u001b[38;5;34m186\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ dense_1[\u001b[38;5;34m187\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ dense_1[\u001b[38;5;34m188\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ dense_1[\u001b[38;5;34m189\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot (\u001b[38;5;33mDot\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ c0 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m),      │     \u001b[38;5;34m33,024\u001b[0m │ dot[\u001b[38;5;34m180\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m),       │            │ s0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)]       │            │ c0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
       "│                     │                   │            │ dot[\u001b[38;5;34m181\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m180\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m180\u001b[0m][\u001b[38;5;34m2\u001b[0m],   │\n",
       "│                     │                   │            │ dot[\u001b[38;5;34m182\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m181\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m181\u001b[0m][\u001b[38;5;34m2\u001b[0m],   │\n",
       "│                     │                   │            │ dot[\u001b[38;5;34m183\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m182\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m182\u001b[0m][\u001b[38;5;34m2\u001b[0m],   │\n",
       "│                     │                   │            │ dot[\u001b[38;5;34m184\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m183\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m183\u001b[0m][\u001b[38;5;34m2\u001b[0m],   │\n",
       "│                     │                   │            │ dot[\u001b[38;5;34m185\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m184\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m184\u001b[0m][\u001b[38;5;34m2\u001b[0m],   │\n",
       "│                     │                   │            │ dot[\u001b[38;5;34m186\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m185\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m185\u001b[0m][\u001b[38;5;34m2\u001b[0m],   │\n",
       "│                     │                   │            │ dot[\u001b[38;5;34m187\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m186\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m186\u001b[0m][\u001b[38;5;34m2\u001b[0m],   │\n",
       "│                     │                   │            │ dot[\u001b[38;5;34m188\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m187\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m187\u001b[0m][\u001b[38;5;34m2\u001b[0m],   │\n",
       "│                     │                   │            │ dot[\u001b[38;5;34m189\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m188\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m188\u001b[0m][\u001b[38;5;34m2\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)        │        \u001b[38;5;34m715\u001b[0m │ lstm_1[\u001b[38;5;34m180\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m181\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m182\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m183\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m184\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m185\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m186\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m187\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m188\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m189\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,960</span> (206.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m52,960\u001b[0m (206.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,960</span> (206.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m52,960\u001b[0m (206.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4-3-3'></a>\n",
    "\n",
    "### 4.3.3. Model Compilation\n",
    "\n",
    "In this section, we define the process of compiling the model after its creation in Keras. The compilation step involves specifying the loss function, optimizer, and evaluation metrics to guide the training process.\n",
    "\n",
    "- **Loss Function**: The chosen loss function is *categorical crossentropy*, commonly used for multi-class classification tasks.\n",
    "\n",
    "- **Optimizer**: The Adam optimizer is selected for its adaptive learning rate properties, which help to accelerate convergence. The specific parameters used in this case are:\n",
    "  - Learning rate: 0.005\n",
    "  - $\\beta_1 = 0.9$ (first moment decay)\n",
    "  - $\\beta_2 = 0.999$ (second moment decay)\n",
    "  - Decay: 0.01 (learning rate decay over each epoch)\n",
    "\n",
    "- **Metric**: The model performance is evaluated using *accuracy*, which is a standard metric for classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "# Define the initial learning rate\n",
    "initial_learning_rate = 0.005\n",
    "\n",
    "# Set up the ExponentialDecay schedule\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate=initial_learning_rate,\n",
    "    decay_steps=10000,  # Number of steps before decay\n",
    "    decay_rate=0.96,    # The rate at which the learning rate decays\n",
    "    staircase=True      # If True, it applies the decay in discrete steps\n",
    ")\n",
    "\n",
    "# Use the learning rate schedule in the optimizer and add beta_1, beta_2\n",
    "opt = Adam(\n",
    "    learning_rate=lr_schedule,\n",
    "    beta_1=0.9,  # Exponential decay rate for the first moment estimate\n",
    "    beta_2=0.999, # Exponential decay rate for the second moment estimate\n",
    ")\n",
    "\n",
    "# Compile the model with the updated optimizer\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()]*10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "# UNIT TESTS\n",
    "assert opt.learning_rate == 0.005, \"Set the lr parameter to 0.005\"\n",
    "assert opt.beta_1 == 0.9, \"Set the beta_1 parameter to 0.9\"\n",
    "assert opt.beta_2 == 0.999, \"Set the beta_2 parameter to 0.999\"\n",
    "assert model.loss == \"categorical_crossentropy\", \"Wrong loss. Use 'categorical_crossentropy'\"\n",
    "assert model.optimizer == opt, \"Use the optimizer that you have instantiated\"\n",
    "print(\"\\033[92mAll tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "<h1 style=\"background: #FFC07F; border: 0; color: #2F2E41; \n",
    "    box-shadow: 4px 4px 8px rgba(0, 0, 0, 0.3); \n",
    "    padding: 10px; border-radius: 10px; margin: 15px 0;\">\n",
    "    <center style=\"color: #2F2E41;\">5. Training the model</center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5-1\"> </a>\n",
    "\n",
    "## 5.1. Define Inputs and Outputs, and Fit the Model\n",
    "\n",
    "The next step involves defining the inputs and outputs necessary for training the model. The following considerations are made:\n",
    "\n",
    "- **Inputs**: The input data, denoted as $X$, has a shape of $(m = 10000, T_x = 30)$, where $m$ represents the number of training examples, and $T_x$ is the sequence length for each example. Each element of $X$ corresponds to a sequence of features for a training sample.\n",
    "\n",
    "- **State Initialization**: To initialize the `post_attention_LSTM_cell`, we define the initial states `s_0` and `c_0`, which are set to zero. These initializations are required to set the initial hidden and cell states of the LSTM before training begins.\n",
    "\n",
    "- **Outputs**: The target outputs, denoted as `outputs`, consist of a list of 10 elements, each with a shape of $(m, T_y)$. Each element in the list corresponds to the true labels for the characters in the sequences. Specifically, for each training example $X[i]$, the list `outputs[i][0], ..., outputs[i][T_y]` represents the true labels for the sequence of characters. Each $outputs[i][j]$ corresponds to the true label of the $j^{th}$ character in the $i^{th}$ training example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = np.zeros((m, n_s))\n",
    "c0 = np.zeros((m, n_s))\n",
    "outputs = list(Yoh.swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now fit the model and run it for one epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 84ms/step - dense_3_categorical_accuracy: 0.3079 - dense_3_categorical_accuracy_1: 0.3079 - dense_3_categorical_accuracy_2: 0.3079 - dense_3_categorical_accuracy_3: 0.3079 - dense_3_categorical_accuracy_4: 0.3079 - dense_3_categorical_accuracy_5: 0.3079 - dense_3_categorical_accuracy_6: 0.3079 - dense_3_categorical_accuracy_7: 0.3079 - dense_3_categorical_accuracy_8: 0.3079 - dense_3_categorical_accuracy_9: 0.3079 - dense_3_loss: 2.6840 - loss: 19.6320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x795361e31190>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([Xoh, s0, c0], outputs, epochs=1, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While training, it is possible to monitor both the loss and accuracy for each of the 10 positions in the output sequence. The table below illustrates an example of the accuracies that could be observed if the batch contained 2 training examples:\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"https://raw.githubusercontent.com/umermjd11/DLC5M3A1/master/images/table.png\" style=\"width:700;height:200px;\">\n",
    "  <br>\n",
    "  <caption>\n",
    "    <font color=\"#00796b\" style=\"font-size: 1.2em; font-weight: bold;\">\n",
    "      For instance, `dense_2_acc_8: 0.89` indicates that the model is correctly predicting the 7th character of the output with an accuracy of 89% for the current batch of data.\n",
    "    </font>\n",
    "  </caption>\n",
    "</div>\n",
    "\n",
    "After training the model for an extended period, the weights have been saved. To save time, we will load the pre-trained weights by running the next cell. Although training a model for several minutes will yield similar accuracy, loading the pre-trained model will expedite the process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('models/model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see the results on new examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "source: 3 May 1979\n",
      "output: 1979-05-33 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "source: 5 April 09\n",
      "output: 2009-04-05 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64278/2649609632.py:12: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  output = [inv_machine_vocab[int(i)] for i in prediction]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: 21th of August 2016\n",
      "output: 2016-08-20 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "source: Tue 10 Jul 2007\n",
      "output: 2007-07-10 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "source: Saturday May 9 2018\n",
      "output: 2018-05-09 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "source: March 3 2001\n",
      "output: 2001-03-03 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "source: March 3rd 2001\n",
      "output: 2001-03-03 \n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "source: 1 March 2001\n",
      "output: 2001-03-01 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "EXAMPLES = ['3 May 1979', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001', '1 March 2001']\n",
    "s00 = np.zeros((1, n_s))\n",
    "c00 = np.zeros((1, n_s))\n",
    "for example in EXAMPLES:\n",
    "    source = string_to_int(example, Tx, human_vocab)\n",
    "    #print(source)\n",
    "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source))).swapaxes(0,1)\n",
    "    source = np.swapaxes(source, 0, 1)\n",
    "    source = np.expand_dims(source, axis=0)\n",
    "    prediction = model.predict([source, s00, c00])\n",
    "    prediction = np.argmax(prediction, axis = -1)\n",
    "    output = [inv_machine_vocab[int(i)] for i in prediction]\n",
    "    print(\"source:\", example)\n",
    "    print(\"output:\", ''.join(output),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "source: 4th of july 2001\n",
      "output: 2001-07-04 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64278/329283865.py:8: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  output = [inv_machine_vocab[int(i)] for i in prediction]\n"
     ]
    }
   ],
   "source": [
    "def translate_date(sentence):\n",
    "    source = string_to_int(sentence, Tx, human_vocab)\n",
    "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source))).swapaxes(0,1)\n",
    "    source = np.swapaxes(source, 0, 1)\n",
    "    source = np.expand_dims(source, axis=0)\n",
    "    prediction = model.predict([source, s00, c00])\n",
    "    prediction = np.argmax(prediction, axis = -1)\n",
    "    output = [inv_machine_vocab[int(i)] for i in prediction]\n",
    "    print(\"source:\", sentence)\n",
    "    print(\"output:\", ''.join(output),\"\\n\")\n",
    "example = \"4th of july 2001\"\n",
    "translate_date(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may also modify these examples to test the model with our own data. The subsequent section will provide deeper insights into the attention mechanism, specifically illustrating which part of the input the network is focusing on when generating a particular output character.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "\n",
    "<h1 style=\"background: #FFC07F; border: 0; color: #2F2E41; \n",
    "    box-shadow: 4px 4px 8px rgba(0, 0, 0, 0.3); \n",
    "    padding: 10px; border-radius: 10px; margin: 15px 0;\">\n",
    "    <center style=\"color: #2F2E41;\">6. Visualizing Attention</center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the task could be approached by using 10 separate softmax units to generate the 10 characters of the output (given the fixed output length), the attention model offers a distinct advantage. Specifically, the attention mechanism allows each part of the output to focus only on a relevant subset of the input, improving the model’s efficiency and accuracy in mapping input to output.\n",
    "\n",
    "To illustrate this, consider the task of translating \"Saturday 9 May 2018\" into \"2018-05-09\". By visualizing the computed attention weights, $\\alpha^{\\langle t, t' \\rangle}$, we obtain the following attention map:\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"https://raw.githubusercontent.com/umermjd11/DLC5M3A1/master/images/date_attention.png\" style=\"width:600;height:300px;\">\n",
    "  <br>\n",
    "  <caption>\n",
    "    <font color=\"#00796b\" style=\"font-size: 1.2em; font-weight: bold;\">\n",
    "      <b>Figure 8</b>: Full Attention Map\n",
    "    </font>\n",
    "  </caption>\n",
    "</div>\n",
    "\n",
    "As shown in the attention map, the model largely ignores the \"Saturday\" portion of the input, as none of the output timesteps pay significant attention to it. We also observe that the number \"9\" is correctly translated as \"09\", and \"May\" is translated into \"05\". The attention mechanism allows the model to focus on the necessary portions of the input, enabling it to accurately generate the output. Notably, the year \"2018\" is primarily constructed by attending to the \"18\" in the input, reflecting the model’s ability to learn dependencies between different parts of the input and output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6-1'></a>\n",
    "\n",
    "## 6.1 - Extracting the Attention Weights from the Network\n",
    "\n",
    "In this section, we focus on visualizing the attention values learned by the network. To achieve this, we will propagate an example through the network and then extract the attention weights, denoted as $\\alpha^{\\langle t, t' \\rangle}$.\n",
    "\n",
    "To begin, we will print a summary of the model to identify the components and layers involved in the attention mechanism.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Attention_Model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Attention_Model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Input_Sequence      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ s0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ BiLSTM              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">17,920</span> │ Input_Sequence[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ repeat_vector       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ s0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)      │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">181</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">183</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">186</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">188</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">18…</span> │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">18…</span> │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">18…</span> │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">18…</span> │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">18…</span> │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">18…</span> │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">18…</span> │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">18…</span> │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">18…</span> │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">18…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>]… │\n",
       "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">181</span>]… │\n",
       "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>]… │\n",
       "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">183</span>]… │\n",
       "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>]… │\n",
       "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>]… │\n",
       "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">186</span>]… │\n",
       "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>]… │\n",
       "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">188</span>]… │\n",
       "│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">189</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">181</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">183</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">186</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">188</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">189</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention_weights   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">181</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">183</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">186</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">188</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">189</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ c0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),       │            │ s0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)]       │            │ c0[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
       "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">181</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],   │\n",
       "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">181</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">181</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],   │\n",
       "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">183</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],   │\n",
       "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">183</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">183</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],   │\n",
       "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],   │\n",
       "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">186</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],   │\n",
       "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">186</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">186</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],   │\n",
       "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">188</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],   │\n",
       "│                     │                   │            │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">189</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">188</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">188</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">715</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">181</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">183</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">184</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">186</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">188</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">189</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Input_Sequence      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m37\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ s0 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ BiLSTM              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m17,920\u001b[0m │ Input_Sequence[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ repeat_vector       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ s0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
       "│ (\u001b[38;5;33mRepeatVector\u001b[0m)      │                   │            │ lstm_1[\u001b[38;5;34m180\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m181\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m182\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m183\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m184\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m185\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m186\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m187\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m188\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ repeat_vector[\u001b[38;5;34m18…\u001b[0m │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ repeat_vector[\u001b[38;5;34m18…\u001b[0m │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ repeat_vector[\u001b[38;5;34m18…\u001b[0m │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ repeat_vector[\u001b[38;5;34m18…\u001b[0m │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ repeat_vector[\u001b[38;5;34m18…\u001b[0m │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ repeat_vector[\u001b[38;5;34m18…\u001b[0m │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ repeat_vector[\u001b[38;5;34m18…\u001b[0m │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ repeat_vector[\u001b[38;5;34m18…\u001b[0m │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ repeat_vector[\u001b[38;5;34m18…\u001b[0m │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ repeat_vector[\u001b[38;5;34m18…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m10\u001b[0m)    │      \u001b[38;5;34m1,290\u001b[0m │ concatenate[\u001b[38;5;34m180\u001b[0m]… │\n",
       "│                     │                   │            │ concatenate[\u001b[38;5;34m181\u001b[0m]… │\n",
       "│                     │                   │            │ concatenate[\u001b[38;5;34m182\u001b[0m]… │\n",
       "│                     │                   │            │ concatenate[\u001b[38;5;34m183\u001b[0m]… │\n",
       "│                     │                   │            │ concatenate[\u001b[38;5;34m184\u001b[0m]… │\n",
       "│                     │                   │            │ concatenate[\u001b[38;5;34m185\u001b[0m]… │\n",
       "│                     │                   │            │ concatenate[\u001b[38;5;34m186\u001b[0m]… │\n",
       "│                     │                   │            │ concatenate[\u001b[38;5;34m187\u001b[0m]… │\n",
       "│                     │                   │            │ concatenate[\u001b[38;5;34m188\u001b[0m]… │\n",
       "│                     │                   │            │ concatenate[\u001b[38;5;34m189\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │         \u001b[38;5;34m11\u001b[0m │ dense[\u001b[38;5;34m180\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ dense[\u001b[38;5;34m181\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ dense[\u001b[38;5;34m182\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ dense[\u001b[38;5;34m183\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ dense[\u001b[38;5;34m184\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ dense[\u001b[38;5;34m185\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ dense[\u001b[38;5;34m186\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ dense[\u001b[38;5;34m187\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ dense[\u001b[38;5;34m188\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ dense[\u001b[38;5;34m189\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention_weights   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m180\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │ dense_1[\u001b[38;5;34m181\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ dense_1[\u001b[38;5;34m182\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ dense_1[\u001b[38;5;34m183\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ dense_1[\u001b[38;5;34m184\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ dense_1[\u001b[38;5;34m185\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ dense_1[\u001b[38;5;34m186\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ dense_1[\u001b[38;5;34m187\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ dense_1[\u001b[38;5;34m188\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ dense_1[\u001b[38;5;34m189\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot (\u001b[38;5;33mDot\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                     │                   │            │ attention_weight… │\n",
       "│                     │                   │            │ BiLSTM[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ c0 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m),      │     \u001b[38;5;34m33,024\u001b[0m │ dot[\u001b[38;5;34m180\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m),       │            │ s0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)]       │            │ c0[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
       "│                     │                   │            │ dot[\u001b[38;5;34m181\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m180\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m180\u001b[0m][\u001b[38;5;34m2\u001b[0m],   │\n",
       "│                     │                   │            │ dot[\u001b[38;5;34m182\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m181\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m181\u001b[0m][\u001b[38;5;34m2\u001b[0m],   │\n",
       "│                     │                   │            │ dot[\u001b[38;5;34m183\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m182\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m182\u001b[0m][\u001b[38;5;34m2\u001b[0m],   │\n",
       "│                     │                   │            │ dot[\u001b[38;5;34m184\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m183\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m183\u001b[0m][\u001b[38;5;34m2\u001b[0m],   │\n",
       "│                     │                   │            │ dot[\u001b[38;5;34m185\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m184\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m184\u001b[0m][\u001b[38;5;34m2\u001b[0m],   │\n",
       "│                     │                   │            │ dot[\u001b[38;5;34m186\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m185\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m185\u001b[0m][\u001b[38;5;34m2\u001b[0m],   │\n",
       "│                     │                   │            │ dot[\u001b[38;5;34m187\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m186\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m186\u001b[0m][\u001b[38;5;34m2\u001b[0m],   │\n",
       "│                     │                   │            │ dot[\u001b[38;5;34m188\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m187\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m187\u001b[0m][\u001b[38;5;34m2\u001b[0m],   │\n",
       "│                     │                   │            │ dot[\u001b[38;5;34m189\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m188\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m188\u001b[0m][\u001b[38;5;34m2\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)        │        \u001b[38;5;34m715\u001b[0m │ lstm_1[\u001b[38;5;34m180\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m181\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m182\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m183\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m184\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m185\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m186\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m187\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m188\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lstm_1[\u001b[38;5;34m189\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">158,881</span> (620.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m158,881\u001b[0m (620.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,960</span> (206.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m52,960\u001b[0m (206.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,921</span> (413.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m105,921\u001b[0m (413.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate through the output of `model.summary()` to observe the details of the model architecture. In particular, note that the layer named `attention_weights` outputs the attention values, denoted as $\\alpha$, with a shape of $(m, 30, 1)$. These attention weights are computed before the `dot_2` layer, which generates the context vector for each time step $t = 0, \\ldots, T_y-1$. We will extract the attention weights from this layer for further analysis.\n",
    "\n",
    "The function `attention_map()` is designed to extract the attention values from the model and visualize them through a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x850 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attention_map = plot_attention_map(model, human_vocab, inv_machine_vocab, \"Tuesday 09 Oct 1993\", num = 7, n_s = 64);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the generated plot, the attention weights for each character of the predicted output are visualized. It is important to examine this plot and verify that the areas where the network is focusing align with our expectations.\n",
    "\n",
    "In the context of the date translation task, we observe that the attention mechanism predominantly aids in predicting the year, while having less impact on the prediction of the day or month. This behavior is typical, as the year often requires greater attention to specific input features, whereas the day and month are more straightforwardly derived from the input.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a>\n",
    "<h1 style=\"background: #FFC07F; border: 0; color: #2F2E41; \n",
    "    box-shadow: 4px 4px 8px rgba(0, 0, 0, 0.3); \n",
    "    padding: 10px; border-radius: 10px; margin: 15px 0;\">\n",
    "    <center style=\"color: #2F2E41;\">7. Conclusion</center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully completed this project. We are now able to implement an attention model and use it to learn complex mappings from one sequence to another. \n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- Machine translation models can be employed to map one sequence to another. These models are versatile and can be applied not only for tasks like translating between languages (e.g., French to English) but also for specialized applications such as date format translation.\n",
    "- The attention mechanism enables a network to focus on the most relevant parts of the input when generating a specific part of the output. This allows the model to selectively attend to important features in the input sequence.\n",
    "- A network utilizing an attention mechanism can translate sequences where the input length, $T_x$, and output length, $T_y$, can vary. This flexibility is crucial for handling a wide range of tasks.\n",
    "- The attention weights, $\\alpha^{\\langle t,t' \\rangle}$, can be visualized to understand which parts of the input the network attends to while generating each output, providing valuable insight into the model's decision-making process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Solution_Neural_machine_translation_with_attention_v4a.ipynb",
   "provenance": []
  },
  "coursera": {
   "schema_names": [
    "DLSC5W3-1A"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
